# 漸進符號 Asymptotic Notation

> 即為**「統計演算法內所需操作步驟的數目。」**
> 

## Introduction

![Untitled](%E6%BC%B8%E9%80%B2%E7%AC%A6%E8%99%9F%20Asymptotic%20Notation%2079aac38e7bb9435ebd513fdbdbb5daea/Untitled.jpeg)

- 有太多因素干擾影響一個演算法的複雜度，假使我們只觀察當輸入資料量 $n$  接近無窮大時，演算法的成長趨勢為何，就很接近所謂**漸進符號（asymptotic notation）**的定義。漸進符號**只關心演算法在極限下的漸進行為**，不同的演算法可能使用相同的漸進符號表示。
- 可捨去複雜度函數中其他較不重要的次項與常數，留下最大次項，「**透過簡單的函數來表述函數接近極限的行為**」，讓複雜度函數更易理解，這就是「漸進符號」的意義。
- 若需要一份方便快速查詢的各個演算法複雜度的筆記，[**可參考此網頁**](https://www.bigocheatsheet.com/)

### $**O$：Big O**

- 通常關心的是演算法「**最糟糕**的情況下」，**「最多」**需要執行多久。Big O 就是描述演算法複雜度上界的漸進符號
- 欲以 Big O 描述其複雜度上界時，必須滿足以下定義：

$f(n)=O(g(n)):∃k>0 ∃n0 ∀n>n0 |f(n)|≤k⋅g(n)$

### $**\Omega$：Big Omega**

- Big Omega 對應成長趨勢的「下界」，定義如下：

$f(n)=Ω(g(n)):∃k>0 ∃n0 ∀n>n0 |f(n)|≥k⋅g(n)$

- 以 $f(n) = 3n + 4$ 為例，有一組 $k = 2;\ g(n) = n;\ n_0 = 0$滿足上式，因此這個演算法在輸入資料夠大時，「**至少**」會達到 $Omega(n)$ 的複雜度，也就是「該演算法的成長趨勢不會比 $g(n)$來得慢」

### $**\Theta$：Big Theta**

- Big Theta 則是 Big O 與 Big Omega **兩個漸進上下界所夾出的範圍**，表示該演算法在輸入資料夠大時，最終的複雜度會成長到這個範圍中。其定義如下：

$f(n)=Θ(g(n)):∃k1>0 ∃k2>0 ∃n0 ∀n>n0 k1⋅g(n)≤|f(n)|≤k2⋅g(n)$

- 繼續以 $f(n)=3n+4$ 為例，同樣有一組 $k1=1; k2=5; g(n)=n; n0=2$，滿足

$∀n≥2, n≤f(n)=3n+4≤5n∀$

可得知，$f(n)=3n+4∈Θ(n)$，表示「該演算法的成長趨勢與 $g(n)=n$相同」（如圖例）

- 圖例
    
    ![Untitled](%E6%BC%B8%E9%80%B2%E7%AC%A6%E8%99%9F%20Asymptotic%20Notation%2079aac38e7bb9435ebd513fdbdbb5daea/Untitled.png)
    

## 常見的複雜度

- $O(1)$：常數時間，演算法執行時間與資料量毫無瓜葛。例如讀取 array 首個元素。
- $O(logn)$：執行時間隨資料量呈對數比例成長。常見的例子是二元搜索（Binary search）。
- $O(n)$：執行時間隨資料量呈線性成長，例如在無序的 array 中尋找特定值。
- $O(nlogn)$：執行時間隨資料量呈線性對數成長，常見的合併排序（Mergesort）的複雜度即如斯。
- $O(n^2)$：執行時間隨資料量呈平方成長，例如一些效率不彰的排序法如氣泡排序（Bubble sort）。
- $O(n^3)$：執行時間隨資料量呈立方成長，常見例子為 naïve 實作的矩陣乘法。
- $O(c^n)$：執行時間隨資料量呈指數成長。
- $O(n!)$：執行時間隨資料量呈階乘成長，大部分情況下，這是非常差勁的複雜度。（ex：如果超過20的話會執行到宇宙滅亡）

[【演算法中的 NP 問題】](https://lkm543.medium.com/%E6%BC%94%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84-np-%E5%95%8F%E9%A1%8C-db976e55b60b)